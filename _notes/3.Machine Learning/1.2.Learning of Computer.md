# 학습 과정
![](https://i.imgur.com/3sJfR4f.png)

컴퓨터는 메타인지 능력이 없음 -> loss function 계산(오답 정리)을 해야 얼마나 틀렸는지 안다.

# Fitting
-  fitting
	- $P_{train}\uparrow \Rightarrow P_{test}\uparrow$
	- 절대적 기준은 없음. 차이가 많이 안 나면 적당히 판단.
- overfitting : 데이터를 전부 외워서 맞춘 상태
	- $P_{train}\uparrow\  \Rightarrow\  P_{test} \downarrow$
	- ex) 데이터 수 $\downarrow$ , 차원이 너무 큼, 외우는 능력이 있는 모델(tree)
	- $P_{test}(f)<P_{test}(g)$
	![](https://i.imgur.com/thWVpVa.png)

 - underfitting
	 - $P_{train}\downarrow \Rightarrow P_{test}\downarrow$
	 - ex) 모델의 능력 부족(linear model에 non-linear data를 넣었을 때)
# Data Split
![](https://i.imgur.com/HaK3DMe.png)

- Training Data : 학습에 사용하는 데이터
- Validation Data : 학습 성능 '확인'에 사용하는 데이터. loss function은 계산하지 않고  $P_{val}$만 계산.
	- Machine Learning의 목적 : prediction for unseen data = $P_{test}$ 결과가 좋은 것  $\rightarrow P_{val}$ : 학습 전략 수정[^1] 기준
	- Training Data 학습만 반복하면 overfitting되고 있는지 알 수 없음 -> 끝나갈 때쯤 validation 필요
	- 데이터의 개수가 적을 때 : test 데이터를 제외한 다른 데이터에 대한 예측 성능을 확신할 수 없으므로 validation데이터가 더 중요해짐.
	- 데이터의 개수가 많을 때 : overfitting이 잘 안 되지만 논리적으로 validation을 거치는 게 좋음
- Test Data : 예측 성능 확인에 사용하는 데이터. validation 데이터만 잘 맞추는 것일 수 있으므로 한 번 더 검증

[^1]: 학습 전략 수정 : model 수정 or hyper-parameter 수정